{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0) Carga de datos, librerias y funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('punkt', download_dir='nltk_data')\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import html\n",
    "import unicodedata\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ENQUESTA_ID</th>\n",
       "      <th>SEMESTRE</th>\n",
       "      <th>PREGUNTA_ID</th>\n",
       "      <th>RESPOSTA_ID</th>\n",
       "      <th>RESPOSTA</th>\n",
       "      <th>IDP</th>\n",
       "      <th>SUMATORI</th>\n",
       "      <th>TIPUS_PREGUNTA</th>\n",
       "      <th>ENQUESTA_CREATED_AT</th>\n",
       "      <th>PREGUNTA_CREATED_AT</th>\n",
       "      <th>RESPOSTA_CREATED_AT</th>\n",
       "      <th>CREATION_DATE</th>\n",
       "      <th>UPDATE_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8774167</td>\n",
       "      <td>668</td>\n",
       "      <td>20232.0</td>\n",
       "      <td>17675</td>\n",
       "      <td>426985</td>\n",
       "      <td>SolicitÃ© un cambio de idioma de docencia y de...</td>\n",
       "      <td>1680015</td>\n",
       "      <td>1</td>\n",
       "      <td>PREGUNTA_OBERTA</td>\n",
       "      <td>2024-03-01 09:14:33</td>\n",
       "      <td>2024-03-01 09:14:40</td>\n",
       "      <td>2024-03-27 16:04:38</td>\n",
       "      <td>2024-08-09 09:49:23.133000</td>\n",
       "      <td>2024-08-09 09:49:23.133000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8774168</td>\n",
       "      <td>670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17738</td>\n",
       "      <td>427070</td>\n",
       "      <td>MejorarÃ­a la velocidad de respuesta por parte...</td>\n",
       "      <td>1265565</td>\n",
       "      <td>1</td>\n",
       "      <td>PREGUNTA_OBERTA</td>\n",
       "      <td>2024-05-22 09:02:23</td>\n",
       "      <td>2024-05-22 09:02:32</td>\n",
       "      <td>2024-06-12 17:38:19</td>\n",
       "      <td>2024-08-09 09:49:23.133000</td>\n",
       "      <td>2024-08-09 09:49:23.133000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8774170</td>\n",
       "      <td>670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17738</td>\n",
       "      <td>427313</td>\n",
       "      <td>Algunas asignaturas estÃ¡n en inglÃ©s porque s...</td>\n",
       "      <td>1418238</td>\n",
       "      <td>1</td>\n",
       "      <td>PREGUNTA_OBERTA</td>\n",
       "      <td>2024-05-22 09:02:23</td>\n",
       "      <td>2024-05-22 09:02:32</td>\n",
       "      <td>2024-06-12 19:49:45</td>\n",
       "      <td>2024-08-09 09:49:23.133000</td>\n",
       "      <td>2024-08-09 09:49:23.133000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8774171</td>\n",
       "      <td>670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17738</td>\n",
       "      <td>427349</td>\n",
       "      <td>A Canvas resulta poc intuÃ¯tiu que els recurso...</td>\n",
       "      <td>1414112</td>\n",
       "      <td>1</td>\n",
       "      <td>PREGUNTA_OBERTA</td>\n",
       "      <td>2024-05-22 09:02:23</td>\n",
       "      <td>2024-05-22 09:02:32</td>\n",
       "      <td>2024-06-12 20:10:34</td>\n",
       "      <td>2024-08-09 09:49:23.133000</td>\n",
       "      <td>2024-08-09 09:49:23.133000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8774172</td>\n",
       "      <td>670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17738</td>\n",
       "      <td>427421</td>\n",
       "      <td>Se necesitan mas profesores vocacionales, y un...</td>\n",
       "      <td>815659</td>\n",
       "      <td>1</td>\n",
       "      <td>PREGUNTA_OBERTA</td>\n",
       "      <td>2024-05-22 09:02:23</td>\n",
       "      <td>2024-05-22 09:02:32</td>\n",
       "      <td>2024-06-12 20:52:45</td>\n",
       "      <td>2024-08-09 09:49:23.133000</td>\n",
       "      <td>2024-08-09 09:49:23.133000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  ENQUESTA_ID  SEMESTRE  PREGUNTA_ID  RESPOSTA_ID  \\\n",
       "0  8774167          668   20232.0        17675       426985   \n",
       "1  8774168          670       NaN        17738       427070   \n",
       "2  8774170          670       NaN        17738       427313   \n",
       "3  8774171          670       NaN        17738       427349   \n",
       "4  8774172          670       NaN        17738       427421   \n",
       "\n",
       "                                            RESPOSTA      IDP  SUMATORI  \\\n",
       "0  SolicitÃ© un cambio de idioma de docencia y de...  1680015         1   \n",
       "1  MejorarÃ­a la velocidad de respuesta por parte...  1265565         1   \n",
       "2  Algunas asignaturas estÃ¡n en inglÃ©s porque s...  1418238         1   \n",
       "3  A Canvas resulta poc intuÃ¯tiu que els recurso...  1414112         1   \n",
       "4  Se necesitan mas profesores vocacionales, y un...   815659         1   \n",
       "\n",
       "    TIPUS_PREGUNTA  ENQUESTA_CREATED_AT  PREGUNTA_CREATED_AT  \\\n",
       "0  PREGUNTA_OBERTA  2024-03-01 09:14:33  2024-03-01 09:14:40   \n",
       "1  PREGUNTA_OBERTA  2024-05-22 09:02:23  2024-05-22 09:02:32   \n",
       "2  PREGUNTA_OBERTA  2024-05-22 09:02:23  2024-05-22 09:02:32   \n",
       "3  PREGUNTA_OBERTA  2024-05-22 09:02:23  2024-05-22 09:02:32   \n",
       "4  PREGUNTA_OBERTA  2024-05-22 09:02:23  2024-05-22 09:02:32   \n",
       "\n",
       "   RESPOSTA_CREATED_AT               CREATION_DATE                 UPDATE_DATE  \n",
       "0  2024-03-27 16:04:38  2024-08-09 09:49:23.133000  2024-08-09 09:49:23.133000  \n",
       "1  2024-06-12 17:38:19  2024-08-09 09:49:23.133000  2024-08-09 09:49:23.133000  \n",
       "2  2024-06-12 19:49:45  2024-08-09 09:49:23.133000  2024-08-09 09:49:23.133000  \n",
       "3  2024-06-12 20:10:34  2024-08-09 09:49:23.133000  2024-08-09 09:49:23.133000  \n",
       "4  2024-06-12 20:52:45  2024-08-09 09:49:23.133000  2024-08-09 09:49:23.133000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruta='data/resultados_enquestes.csv'\n",
    "df=pd.read_csv(ruta,sep=',')\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_column_name ='RESPOSTA'\n",
    "text_data = df[text_column_name].tolist()\n",
    "print(type(text_data))\n",
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''  \n",
    "    text = html.unescape(text)\n",
    "    text = text.lower()\n",
    "    text = unicodedata.normalize('NFD', text)\n",
    "    text = ''.join(c for c in text if not unicodedata.combining(c))\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\@\\w+|\\#', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "cleaned_data = [clean_text(doc) for doc in text_data]\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_catalan = [\n",
    "    'i', 'de', 'a', 'la', 'el', 'en', 'que', 'no', 'un', 'per', 'amb', 'els', 'les', 'dels', 'al', 'del', 'com', 'una', 'o', 'a', 'abans', 'ací', 'això', 'així', 'al', 'alguna', 'algunes', 'alguns', 'allà', 'allí', \n",
    "    'allò', 'als', 'altra', 'altre', 'altres', 'amb', 'aquell', 'aquella', 'aquelles', 'aquells', \n",
    "    'aquest', 'aquesta', 'aquestes', 'aquests', 'ben', 'cada', 'com', 'contra'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtm_(cleaned_data):\n",
    "    vectorizer = CountVectorizer(stop_words=stopwords_catalan, token_pattern=r'\\b[a-zA-Z]+\\b', min_df=10)\n",
    "    dtm = vectorizer.fit_transform(cleaned_data)\n",
    "    return dtm, vectorizer\n",
    "\n",
    "dtm, vectorizer=dtm_(cleaned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Tópicos de Palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_find_n_v1(dtm):\n",
    "    search_params = {'n_components': [4, 5, 6, 7, 8, 9, 10,11,12,13,14,15]}\n",
    "    lda = LatentDirichletAllocation()\n",
    "    model = GridSearchCV(lda, param_grid=search_params)\n",
    "    model.fit(dtm)\n",
    "    print(\"Mejor número de temas:\", model.best_params_)\n",
    "    print(\"Log-Likelihood del mejor modelo:\", model.best_score_)\n",
    "\n",
    "lda_find_n_v1(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_find_n_v2(dtm):\n",
    "    dtm_train, dtm_test = train_test_split(dtm, test_size=0.25, random_state=42)\n",
    "    lda = LDA(n_components=7, random_state=42)\n",
    "    lda.fit(dtm_train)\n",
    "    perplexity_train = lda.perplexity(dtm_test)\n",
    "    print(perplexity_train)\n",
    "    k_values = [2, 4, 8, 16]\n",
    "    perplexities = []\n",
    "\n",
    "    for k in k_values:\n",
    "        print(k)\n",
    "        lda = LDA(n_components=k, random_state=42)\n",
    "        lda.fit(dtm_train)\n",
    "        perplexity = lda.perplexity(dtm_test)\n",
    "        perplexities.append(perplexity)\n",
    "\n",
    "    plt.plot(k_values, perplexities, marker='o')\n",
    "    plt.xlabel('Número de temas (k)')\n",
    "    plt.ylabel('Perplejidad')\n",
    "    plt.title('Perplejidad para diferentes valores de k')\n",
    "    plt.show()\n",
    "\n",
    "lda_find_n_v2(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda(n, vectorizer):\n",
    "    lda = LDA(n_components=n, random_state=42)\n",
    "    lda.fit(dtm)\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    topic_words = {}\n",
    "    for topic_idx, topic in enumerate(lda.components_):\n",
    "        top_terms_idx = topic.argsort()[-40:][::-1]  # Obtener los índices de las 40 palabras más importantes\n",
    "        top_terms = [terms[i] for i in top_terms_idx]\n",
    "        topic_words[topic_idx] = top_terms\n",
    "\n",
    "    print(topic_words)\n",
    "\n",
    "    return topic_words\n",
    "\n",
    "lda(4, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Analisis de Sentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sample(5)\n",
    "comentarios=df['RESPOSTA'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import logging\n",
    "logging.set_verbosity(logging.WARNING)\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=pipeline('sentiment-analysis', model='nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "sentimiento_predicho=classifier(comentarios)\n",
    "for comentarios, sentimiento_predicho in zip(comentarios, sentimiento_predicho):\n",
    "  print(f\"comentario: {comentarios}\\nPredicted Sentiment: {sentimiento_predicho['label']} (Confidence: {sentimiento_predicho['score']:.4f})\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Tradución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your input_length: 178 is bigger than 0.9 * max_length: 50. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 305 is bigger than 0.9 * max_length: 50. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 132 is bigger than 0.9 * max_length: 50. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: trobo a faltar serveis d&#039;atenciÃ³/ajuda psicolÃ²gica\n",
      "Translated: serviceis missing d=039;psychological care\n",
      "\n",
      "Original: El sistema de gestiÃ³ de les prÃ ctiques Ã©s el que queda mÃ©s fluix amb diferÃ¨ncia\n",
      "Translated: The management system of the most fluix amb differentiÃ ncia\n",
      "\n",
      "Original: Falta un telÃ¨fon d&#039;atenciÃ³ a l&#039;estudiant, a vegades hi ha dubtes quÃ¨ es fa difÃ­cil explicar per correu. A mÃ©s, al telÃ¨fon la resposta Ã©s al moment per correu no. Trobo quÃ¨ un telÃ¨fon d&#039;atenciÃ³ al client seria de molta utilitat. \\ Falten classes onlines, com per exemple, la UNIR ofereix classes magistrals online, que crec necessÃ ries per a l&#039;aprenantage. Ãs insuficient donar tan sols un PDF.\n",
      "Translated: It is difficult to explain per correu. Moreover, to the telephone the answer is to the moment per correu no. Trobo what a telephone d=039; it is difficult to explain per correu.\n",
      "\n",
      "Original: Estic satisfeta amb la formaciÃ³, a excepciÃ³ de la metodologia de treball colÂ·laboratiu que implica realitzar PACs amb altres persones. \\  \\ He tingut molt males experiÃ¨ncies en l&#039;elaboraciÃ³ de les PACs. Hi ha persones que no tenen el teu mateix grau de compromÃ­s ni interÃ¨s per fer el mÃ¡ster. Penso que l&#039;entorn virtual et permet la flexibilitat de poder gestionar el teu temps i la dedicaciÃ³ en funciÃ³ a la teva situaciÃ³ personal. PerÃ² al fer treballs en grup, m&#039;he trobat que he hagut d&#039;assumir situacions personals que no sÃ³n la meva, i he trobat repercussiÃ³ negativa en les notes degut a aquestes agrupacions. \\  \\ Prego si us plau que reviseu la metodologia i repenseu com elaborar un treball mÃ©s individualitzat en els reptes, encara que en determinats moments es treballi en xarxa.\n",
      "Translated: Estic satisfieda amb la formaciÃ3, a exceptió de la methodologia de treball colaboratiu que confien realitzar PACs amb altres persones.\n",
      "\n",
      "Original: Estic satisfeta amb el mÃ ster i amb les assignatures. PerÃ² gens satisfeta amb l&#039;organitzaciÃ³ i gestiÃ³ del TFM i els seus temps i tot el que exigeixen les entregues de les PAC&#039;S, ho veig ilÂ·lÃ²gic i incoherent, tampoc estic d&#039;acord en la gestiÃ³ del prÃ cticum i les dates de les memÃ²ries.\n",
      "Translated: Estic satisfiada amb el mÃ ster i amb les assignatures. PerÃ2 gens satisfiada amb lÃ039;organització i gestión\n",
      "\n"
     ]
    }
   ],
   "source": [
    "translator=pipeline('translation', model='Helsinki-NLP/opus-mt-es-en')\n",
    "translated_reviews = [translator(comment, max_length=50)[0]['translation_text'] for comment in comentarios]\n",
    "\n",
    "for original, translated in zip(comentarios, translated_reviews):\n",
    "    print(f\"Original: {original}\")\n",
    "    print(f\"Translated: {translated}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.data.path.append('C:\\\\Users\\\\asanchezbelb\\\\Desktop\\\\UOC\\\\XaviNPL\\\\nltk_data')\n",
    "# Verificar que el recurso 'punkt' está disponible\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "    print(\"Recurso 'punkt' está disponible.\")\n",
    "except LookupError:\n",
    "    print(\"Recurso 'punkt' no está disponible.\")\n",
    "\n",
    "import spacy\n",
    "\n",
    "# Cargar los modelos de idioma\n",
    "nlp_es = spacy.load(\"es_core_news_sm\")\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "nlp_ca = spacy.load(\"ca_core_news_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize_text(text):\n",
    "#     doc = nlp_es(text)\n",
    "#     tokens = [token.text for token in doc]\n",
    "    \n",
    "#     return tokens\n",
    "#     doc = nlp(text)\n",
    "#     tokens = [token.text for token in doc]\n",
    "    \n",
    "#     return tokens\n",
    "\n",
    "# tokenized_data = [tokenize_text(doc) for doc in cleaned_data]\n",
    "\n",
    "# # Imprimir los resultados\n",
    "# for idx, tokens in enumerate(tokenized_data):\n",
    "#     print(f\"Documento {idx+1}: {tokens}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
